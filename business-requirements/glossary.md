# **Glossary**

| **Term** | **Description** |
|----------|---------------|
| **AI Gateway** | A centralized interface that facilitates secure and optimized interactions between the grading system and external AI models, ensuring **cost efficiency, security, and compliance**. |
| **Human-in-the-Loop (HITL)** | An approach where AI-generated evaluations are **validated or refined by expert architects**, ensuring grading accuracy, reducing biases, and maintaining certification credibility. |
| **Multi-Model Strategy** | A grading approach where **different AI models are used to evaluate specific types of artifacts** in case study submissions, improving accuracy and adaptability. |
| **Content Segregator** | An AI-driven system that **categorizes candidate submissions into different document types** (e.g., requirements, architectural decisions, C2 diagrams) for targeted evaluation. |
| **Benchmarking Scores** | Standardized grading metrics used by AI to **assess architectural artifacts** based on industry best practices, quality attributes, and technical correctness. |
| **Retrieval-Augmented Generation (RAG)** | An AI method where **historical correct and incorrect responses are retrieved and used as context** to enhance answer evaluation and grading accuracy. |
| **Adaptive Learning Mechanism** | A system where AI models **continuously learn from expert modifications**, refining grading accuracy and aligning with evolving certification standards. |
| **Trend-Based Question Generation** | An AI-driven approach that **monitors emerging industry trends and generates new certification questions**, ensuring exams remain up-to-date and relevant. |
| **Case Study Rotation** | A security measure where **new case studies are periodically introduced**, preventing exam content leaks and ensuring candidates face fresh challenges. |
| **Confidence-Based Review** | A grading mechanism where **AI assigns confidence scores to evaluations**, flagging low-confidence responses for expert validation. |
